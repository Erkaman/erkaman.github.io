
$\newcommand{\myr}{\mathbb{R}}$
$\newcommand{\myrt}{\mathbb{R}^3}$
$\newcommand{\myrs}{\mathbb{R}^2}$

$\newcommand{\vec}[1]{\mathbf{#1}}$
<h1>Harmonic Mapping: A Tutorial and Introduction</h1>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config(
  {
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
  TeX: { equationNumbers: { autoNumber: "AMS" } }

  });
</script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<p>A week, published a reference implemenation of automatic UV mapping
using harmonic mapping. In the README of that repo, I promised that I
would write an article that explains how the code works. So in this
  article I shall do precisely that.</p>

<p>

  Before I begin I just want to warn you that I have mostly a computer
  science background, and mathematics is not my main area of
  expertise. As a result of this I may sometimes acidentaly write
  things that are not entirely mathematically correct. But anyone who finds any such
  mistakes are very much welcome to email me corrections

</p>

<h2>The Name of the Game</h2>

TODO: image of uv unmapped mesh here.

<p>
But before I can describe automatic UV mapping, I think it is
necessary that we precisely understand what is UV mapping. UV mapping is
simply about finding a mapping from three dimensional space into two
dimensional space. Given any point on the surface of some mesh in three dimensional
space, we want to be able to find some corresponding point in two
dimensional space. Let us denote this mapping by the function
$f$. Since $f$ maps from the three dimensional space to two
dimensional space, the type of $f$ is $\myrt \mapsto
\myrs$.
</p>

<p>
In UV-mapping we implement this mapping follow: In every vertex, in
addition to storing the three dimensional coordinates $(x,y,z) \in
\myrt$, we also store the corresponding two dimensional coordinates
$(u,v) \in \myrs$. With that, we can easily for some vector $\vec{p} \in
\myrt$ evaluate $f(\vec{p})$ as follows: $\vec{p}$ since is on the
surface of the mesh, $\vec{p}$ will be inside some triangle on the
mesh. We can now use the barycentric coordinates of $\vec{p}$
within that triangle to interpolate between the UV-coordinates of the
three vertices of that triangle. This is UV-mapping.
</p>

<p>
The above procedure can easily be implemented in existing graphics
APIs. The barycentric interpolation can be implemented simply by
outputting the UV-coordinates of every vertex from the vertex
shader. Then, for the fragments evaluated in the fragment shader, every
fragment will have the interpolated UV coordinates.
</p>

<p>
The attractive part of UV mapping is that it is dead simple to
implement, and it is fast, assuming that you have already performed
the UV mapping process. However, the main problem in the technique is
exactly how we obtain the mapping.
</p>

<p>
As can be seen in the image above, the UV mapped vertices in $\myrs$ form
triangles that correspond to the triangles of the original mesh in
$\myrt$. For an UV mapping to be considered good, we want that the
original triangles correspond as well as possible to the UV-mapped
triangles. Because if some triangle on $S$ is large, while its
correponding triangle in $\Omega$ is small, then there will not be
enough pixels for that large triangle when applying a texture onto
that mesh. So the texture would in that case become blurry!

<p><a href="/img/harmonic_map/mask_arrow.svg"><img class="article-img" src="/img/harmonic_map/mask_arrow.png"
alt="Mask Arrow"
title="Mask Arrow"
/></a></p>

TOOD: image that illustrates blurry texture.

</p>


<h2>Harmonic Mapping</h2>

<p>
Now I will implement one simple technique for finding such a
mapping. There are several properties we would want such a mapping to
have.

ONE: isometric. The lengths of the triangle edges are preserved by the
mapping.

TWO: conformal. The angles between the triangle edges are preserved by
the mapping.
</p>

<p>
But in this technique, we will focus on preserving the second
property. We will say that when a mapping fails to preserve this
property for some triangles, that there is <i>distortion</i> in those
triangles. Obviously, we want to minimize the distortion.
</p>

<p>
Harmonic mapping works as follow: let us define a mathematical
function whose value is small when there is little distortion. Let us
also assume that there are couple of vertices that form a boundary on
the mesh. The edges that are only adjacent to only one face are the
boundary edges, and all vertices that are at the endpoints of these
forms the boundary. For harmonic mapping to work, we must place these
vertices onto a convex polygon. In other words, their UV-coordinates must be on
some convex polygon. For simplicity, let us a put them on a
circle.

<p><a href="/img/harmonic_map/mask_border_together2.svg"><img class="article-img" src="/img/harmonic_map/mask_border_together.png"
alt="Mesh Border"
title="Mesh Border"
/></a></p>

</p>

<p>

At this point, we know the UV-coordinates of the border vertices, and
we need to know the values for the interior vertices. To find those,
we will define a function that is minimal when the UV-coordinates of
the interior vertices are chosen such that the distortion is minimal.

</p>

<p>
Let the UV-coordinates of the interior vertices be $(\vec{v_1},
\vec{v_2},\dots,\vec{v_n})$ and the UV-coordinates of the boundary
vertices be $(\vec{v}_{n+1},\dots,\vec{v}_{n+b})$. So that there are
$b$ boundary vertices and $n$ interior vertices. Where every vertex
has both a $u$ and $v$ value, and we denote these values $\vec{v_i} =
(u_i, v_i)$. Let $E$ be the set of
all edge indices. So that if there is an edge between the vertices
with indices $i$ and $j$, then $(i,j) \in E$ and $(j, i) \in E$. Now we define the function

\begin{align*}
E(\vec{v}_1,\dots,\vec{v}_{n}) = \frac{1}{2} \sum_{(i,j)\in E} w_{ij} |\vec{v}_j - \vec{v}_i|^2
\end{align*}

So we are basically doing a weighted sum over all vertices based on
the distances between the vertices that are connected by an edge. And
we multiply by the factor $\frac{1}{2}$, because the sum counts every
edge twice(can you see why?), so we need to divide by two to get the
correct sum. If we cleverly choose the values of the weights $w_{ij}$,
minimizing $E$ will yield us a mappping that strives to be
conformal. I later will describe how to choose the weights. But for
now, I will show how we can minimize $E$. I will follow the recipe

</p>

<ol>
  <li>We start with the expression for $E$</li>
  <li>Lots of math happens here in this step.</li>
  <li>We end up with two matrix equations $\vec{Mu=b_u}$ and
  $\vec{Mv=b_v}$, where $\vec{u}$ and $\vec{v}$ are the values of the
  UV-coordinates that minimize $E$. Now just solve both equations with
  some linear solver(say, using a direct solver with <a href="https://en.wikipedia.org/wiki/LU_decomposition">LU decomposition
</a> or a iterative solver based on <a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method">Conjugate gradient</a>) and we are done.</li>
</ol>

<p>
When minimizing functions like this, it is very common that you
convert the problem of minimization into some kind of standard
problem. Because often the function you wish to minimize is very
specific for the problem at hand, and there are often no solvers that
can help in solving them. However, if we convert the problem into well
a well known problem, here the problem of solving a linear system,
then we can simply feed the problem into some solver for that standard
problem.

</p>

<p>
If you have not seen this kind of pattern before, be sure to
rememeber it! This is a very powerful pattern and used in scientific
papers all the time.
</p>

<p>

So now I will show how step 2 in the recipe is implemented. First I
expand the squared vector norm:

\begin{align}
E(\vec{v}_1,\dots,\vec{v}_{n}) =& \nonumber \\
& \frac{1}{2} \sum_{(i, j)\in E} w_{ij} |\vec{v}_j - \vec{v}_i|^2 = \nonumber\\
& \frac{1}{2} \sum_{(i, j)\in E} w_{ij} ((u_j - u_i)^2 + (v_j - v_i)^2)
\label{eq:ebefore}
\end{align}


Now, the next step is a bit non-obvious. And most the literature don't
really explain this part at all, so I shall carefully go
through it. Observe that $E$ is a function of variables $2n$:
$u_1,\dots,u_n$ and $v_1,\dots,v_n$. We can compute the partial
derivative of $E$ with respect to all the variables. Those partial
derivatives are

\begin{equation*}
\frac{\partial E}{\partial u_1},\dots,\frac{\partial E}{\partial u_n}, \frac{\partial E}{\partial v_1},\dots,\frac{\partial E}{\partial v_n},
\end{equation*}


And we know from calculus, that $E$ is either at a maximma, a minima or a
saddle point at the point where <i>all</i> the partial derivatives are
zero. However, I claim that $E$ can <i>only</i> be minimal at that
point! I shall give an inuitive argument for this:

Observe that $E$ is just a sum of terms on the form

\begin{equation*}
w_{ij}((u_j - u_i)^2 + (v_j - v_i)^2)
\end{equation*}

And  $w_{ij}$ is constant and not variable. We
will be making sure that the weights $w_{ij}$ are positive
later. Knowing that $w_{ij}>0$, what is then the graph of:

\begin{equation*}
y = w_{ij}((u_j - u_i)^2 + (v_j - v_i)^2)
\end{equation*}

if we plot with $u_j$ as the x-axis? Let us first expand the
expression for $y$

\begin{align*}
y &= w_{ij}(u_j^2 - 2u_iu_j + u_i^2) + w_{ij}(v_j^2 - 2v_iv_j + v_i^2) \\
  &= w_{ij}u_j^2 - (2u_iw_{ij})u_j + (w_{ij}u_j^2 + w_{ij}(v_j^2 - 2v_iv_j + v_i^2))
\end{align*}


Now let us assign $C = (w_{ij}u_j^2 + w_{ij}(v_j^2 - 2v_iv_j + v_i^2))$,
$B = 2u_iw_{ij}$ and $A=w_{ij}$. And then we get

\begin{equation*}
y = Au_j^2 + Bu_j + C
\end{equation*}

Where all of $A$, $B$ and $C$ are constant. We can see that $y$ is the
equation of a second grade equation. So $y$ is now either a
hill-shaped or a valley-shaped parabola. But since $w_{ij} > 0$ we
have $A > 0$, and therefore

\begin{equation*}
\frac{\partial^2 E}{\partial v_j^2} = 2A > 0
\end{equation*}

so second derivative is positive! But that means that if there is some
extrema at some point, that means it must be a minima. But since
$y$ is a second grade equation it has exactly one extrema, and so we must have that $y$
has exactly one minimum point! And we find that point by finding the
point at which the first derivative is 0. So, to put it in pictures,
$y$ must look like this:

</p>

INSERT LATEX IMAGE HERE.

<p>

and the minimum point of that picture is the point where the first
derivative is zero.

Now, the important thing here is that $E$ is just a sum of these
valley-shaped parabolas. Observe that if we add together to such
valley-shaped parabolas, we just get another valley-shaped
parabola. For if we let $Ax^2 + Bx + C, A > 0$ be one such parabola, and let
$Dx^2 + Ex + F, D>0$ be another such parabola. Then the sum of them is
just

\begin{equation*}
(A+D)x^2 + (B+E)x + (C + F)
\end{equation*}

And this is sum is also a valley-shaped parabola, since $A+D > 0$.

</p>

<p>

The conclusion of the above is that since $E$ is just a sum of
valley-shaped parabolas, also the sum of those valley-shaped parabolas
is also a valley-shaped parabola. And we can easily find the minima of
that parabola by finding the point at which all the partial
derivatives are zero!

</p>

<p>

So let us then find the partial derivatives of equation
$\eqref{eq:ebefore}$. But I shall just show to do it in terms of
$u_1,\dots,u_n$, because the process is identical for
$v_1,\dots,v_n$.

Ok, so let $u_i$ be an arbitrary UV-coordinate. It will be one of
$u_1,\dots,u_n$. Let us find $\frac{\partial E}{\partial u_i}$. Observe,
again, that $E$ is just a sum of terms in the form:

\begin{equation}
w_{ij}((u_j - u_i)^2 + (v_j - v_i)^2)
\label{eq:form}
\end{equation}

But $(v_j−v_i)^2$ will be considered a constant when we are partially
differenriating with respect to $u_i$, so it will disappear. And we
apply the chain rule to differentiate $(u_j - u_i)^2$, and this causes
the the two to be moved down, and the inner derivative is just 1, so

\begin{equation*}
\frac{\partial E}{\partial u_i} = \frac{1}{2} \sum_{j \in N(i)}
2w_{ij} (u_j - u_i) = \sum_{j \in N(i)} w_{ij} (u_j - u_i)
\end{equation*}

Also, note that I have replaced $(i,j) \in E$ with $j \in N(i)$, where
$N(i)$ is the set of all neighbours of $i$. Because it is only in the
adjacent edges of $i$ that contribute a term to the sum. For all
remaining edges, the variable $u_i$ will not appear anywhere, so they
become zero when we take the partial derivative. Therefore, only the
adjacent edges contributes to the partial derivative.

<p/>

<p>
Now that we have computed the partial derivatives, we are now almost
there. We now have in our hands all the pieces that we need to puzzle
together a nice matrix equation. First, if we want to minimize the
harmonic energy, then for all $i=1,\dots,n$ we must have

\begin{equation*}
\frac{\partial E}{\partial u_i} = \sum_{j \in N(i)} w_{ij} (u_j - u_i)
= 0
\end{equation*}

because then $E$ is minimal. However, we also know that all the
boundary vertices have been placed in a unit circle. So we can
describe all the boundary vertices by polar coordinates as
$(u_i,v_i)=(\cos\theta_i, \sin\theta_i), i=n+1,\dots,n+b$. To
summarize, we have

\begin{align*}
\sum_{j \in N(i)} w_{ij} (u_j - u_i)
&= 0, &i = &1,\dots,n \\
u_i &= \cos\theta_i, &i = &n+1,\dots,n+b
\end{align*}

We now have $n+b$ equations of $n+b$ variables. Let $\vec{\bar u}$ be the right-hand of all
those equations. It is a $(n+b)\times 1$ column vector where

\begin{align*}
\vec{\bar u_i} &= 0, &i = &1,\dots,n \\
\vec{\bar u_i} &= \cos\theta_i, &i = &n+1,\dots,n+b
\end{align*}

And we already know that $\vec{u}$ is a $(n+b)\times 1$ column vector
such that $\vec{u} = (u_1,\dots,u_{n+b})$. Let us now find a matrix
$M$ that captures the left-hand side of the equations above, so that
solving the linear system $M\vec{u=\bar u}$ would yield us the
U-coordinates that minimizes the harmonic energy. Note row $i$ in
the matrix $M$ should capture all the information on the
left-hand side of equation $i$. Let us first look at
already know the border vertices. But we already know that these are
projected onto the unit circle, so we can simply set $m_{ii}=1$ and
let all other entires in row $i$ be 0, when $i = n+1,\dots,n+b$. This
has the result that $u_i$ is assigned to $\cos\theta_i$ for the border
vertices, which is just what we want.

</p>

Now let us see how we deal with the internal vertices. I will explain
through an example: Let $E=\{0,1,2,3,4,5,6\}$, let $i=0$ and let $N(i)=\{1,2,3\}$. What does
row $i$ in $M$ look like? Let us expand the left-hand side for $i$:

\begin{align*}
\sum_{j \in N(i)} w_{ij} (u_j - u_i)
&= \\
\sum_{j \in \{1,2,3\} } w_{0j} (u_j - u_0)
&= \\
&= w_{01}u_1 + w_{02}u_2 + w_{03}u_3 - (w_{01} + w_{02} + w_{03})u_0
\end{align*}

So this means that for row 0, $m_{00}$ is the negative sum of all the
weights of the adjacent edges. And $m_{01}=w_{01}$, $m_{02}=w_{02}$
and $m_{03}=w_{03}$. Meaning that for the adjacent edges, the entry in
the matrix is just the weight for those adjacent edges. Finally, for
the remaining columns we have $m_{04} = m_{05} = m_{06} = 0$. So for
the vertices that are not connected to $i$, then the corresponding
entry in the row is 0.

If we now repeat the same process for the remaining rows
$i=1,\dots,n$, we will have formulated the matrix $M$, and can then
solve the linear system and find the UV-coordinates!
